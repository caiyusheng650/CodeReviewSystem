import os
import json
import dotenv
import asyncio
import time
import aiofiles
from pathlib import Path
from typing import List, Dict, Any

# AutoGen v0.7.5 imports
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.teams import DiGraphBuilder, GraphFlow
from autogen_agentchat.ui import Console

from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import ModelFamily


# Load .env
dotenv.load_dotenv()

# ---------------------------
# 1) Model client
# ---------------------------
API_MODEL_NAME = os.getenv("AI_MODEL")
API_API_KEY = os.getenv("AI_API_KEY")
API_API_BASE = os.getenv("AI_API_URL")

print(API_MODEL_NAME)
print(API_API_KEY)
print(API_API_BASE)

model_client = OpenAIChatCompletionClient(
    model=API_MODEL_NAME,
    api_key=API_API_KEY,
    base_url=API_API_BASE,
    model_info={
        "vision": False,
        "function_calling": True,
        "json_output": True,
        "family": ModelFamily.UNKNOWN,
        "structured_output": False,
    },
    max_retries=2,
    response_format={"type": "json_object"}

)

# ---------------------------
# 2) Prompts
# ---------------------------

JSON_ONLY_INSTRUCTION = "\n\né‡è¦æç¤ºï¼šæ‚¨å¿…é¡»ä»…è¾“å‡ºä¸€ä¸ªæœ‰æ•ˆçš„ JSON å¯¹è±¡ï¼Œé™¤æ­¤ä¹‹å¤–ä¸è¦è¾“å‡ºä»»ä½•å†…å®¹ã€‚å¦‚é‡ä¼˜è´¨ä»£ç ï¼Œä¹Ÿå¯ç»™äºˆè¡¨æ‰¬ã€‚"
SYSTEM_PROMPTS: Dict[str, str] = {
    "reputation_assessment_agent": (
        """
You are ReputationAssessmentAgent â€” a code-review reputation & risk assessor.
Output schema:
{
  "risk_level": "high|medium|low|praise",
  "focus_areas": ["security","logic","performance",...],
  "notes": "short explanation"
}
""" + JSON_ONLY_INSTRUCTION
    ),

    "review_task_dispatcher_agent": (
        """
You are ReviewTaskDispatcherAgent.
You must output tasks with correct labels.
Output schema:
{
  "tasks": {
    "static": {"label":"[TO:static]","instruction":"..."},
    "logic": {"label":"[TO:logic]","instruction":"..."},
    "memory": {"label":"[TO:memory]","instruction":"..."},
    "security": {"label":"[TO:security]","instruction":"..."},
    "performance": {"label":"[TO:performance]","instruction":"..."},
    "maintainability": {"label":"[TO:maintainability]","instruction":"..."},
    "architecture": {"label":"[TO:architecture]","instruction":"..."},
  }
}
""" + JSON_ONLY_INSTRUCTION
    ),

    "static_analysis_agent": (
        """
You are StaticAnalysisReviewAgent.
Output: JSON array of issues.
Each item:
{
  "file":"...",
  "line": 123,
  "bug_type": "static_defect",
  "description":"...",
  "suggestion":"...",
  "severity":"è½»åº¦|ä¸­ç­‰|ä¸¥é‡|è¡¨æ‰¬"
}
""" + JSON_ONLY_INSTRUCTION
    ),

    "logic_error_agent": (
        """
You are LogicErrorReviewAgent.
Use bug_type:"logical_defect".
""" + JSON_ONLY_INSTRUCTION
    ),

    "memory_safety_agent": (
        """
You are MemorySafetyReviewAgent.
Use bug_type:"memory_defect".
""" + JSON_ONLY_INSTRUCTION
    ),

    "security_vulnerability_agent": (
        """
You are SecurityVulnerabilityReviewAgent.
Use bug_type:"security_vulnerability".
""" + JSON_ONLY_INSTRUCTION
    ),

    "performance_optimization_agent": (
        """
You are PerformanceOptimizationReviewAgent.
Use bug_type:"performance_issue".
""" + JSON_ONLY_INSTRUCTION
    ),


    "maintainability_agent": (
        """
You are MaintainabilityReviewer.
Use bug_type:"maintainability_issue".
""" + JSON_ONLY_INSTRUCTION
    ),

    "architecture_agent": (
        """
You are ArchitectureReviewer.
Use bug_type:"architecture_issue".
""" + JSON_ONLY_INSTRUCTION
    ),


    "final_review_aggregator_agent": (
        """
You are FinalReviewAggregatorAgent.
You merge all JSON arrays into a single list.

Rules:
1. Parse every message as JSON array. Ignore if fail.
2. Merge arrays.
3. Deduplicate by (file, line, bug_type).
4. If duplicates exist, keep the one with highest severity.
5. Minimize duplicate comments
6. Output only the final JSON array.

IMPORTANT: Output ONLY JSON. æœ€åçš„è¾“å‡ºè¯·ç”¨ä¸­æ–‡ï¼Œä¸‡åˆ†æ„Ÿè°¢ã€‚
"""
    ),
}

# ---------------------------
# 3) Agents
# ---------------------------

def build_agent(name: str, key: str):
    return AssistantAgent(
        name,
        model_client=model_client,
        system_message=SYSTEM_PROMPTS[key],
    )

reputation_assessment_agent = build_agent("ReputationAssessmentAgent", "reputation_assessment_agent")
review_task_dispatcher_agent = build_agent("ReviewTaskDispatcherAgent", "review_task_dispatcher_agent")
static_analysis_agent = build_agent("StaticAnalysisReviewAgent", "static_analysis_agent")
logic_error_agent = build_agent("LogicErrorReviewAgent", "logic_error_agent")
memory_safety_agent = build_agent("MemorySafetyReviewAgent", "memory_safety_agent")
security_vulnerability_agent = build_agent("SecurityVulnerabilityReviewAgent", "security_vulnerability_agent")
performance_optimization_agent = build_agent("PerformanceOptimizationReviewAgent", "performance_optimization_agent")
maintainability_agent = build_agent("MaintainabilityReviewer", "maintainability_agent")
architecture_agent = build_agent("ArchitectureReviewer", "architecture_agent")
final_review_aggregator_agent = build_agent("FinalReviewAggregatorAgent", "final_review_aggregator_agent")

# ---------------------------
# 4) Graph
# ---------------------------

builder = DiGraphBuilder()

agents = [
    reputation_assessment_agent,
    review_task_dispatcher_agent,
    static_analysis_agent,
    logic_error_agent,
    memory_safety_agent,
    security_vulnerability_agent,
    performance_optimization_agent,
    maintainability_agent,
    architecture_agent,
    final_review_aggregator_agent,
]

for a in agents:
    builder.add_node(a)

# Execution edges
builder.add_edge(reputation_assessment_agent, review_task_dispatcher_agent)

reviewers = [
    static_analysis_agent,
    logic_error_agent,
    memory_safety_agent,
    security_vulnerability_agent,
    performance_optimization_agent,
    maintainability_agent,
    architecture_agent,
]

for r in reviewers:
    builder.add_edge(review_task_dispatcher_agent, r)
    builder.add_edge(r, final_review_aggregator_agent)

execution_graph = builder.build()

# ---------------------------
# 5) Build prompt
# ---------------------------

def build_prompt(
    code_diff: str,
    pr_comments: List[Dict[str, Any]],
    developer_reputation_score: int,
    developer_reputation_history: List[str],
    repository_readme: str,
) -> str:

    comments_preview = pr_comments[:20]
    history_preview = developer_reputation_history[:10]

    if developer_reputation_score >= 80:
        rep_label = "high"
    elif developer_reputation_score >= 60:
        rep_label = "medium"
    else:
        rep_label = "low"

    payload = {
        "metadata": {
            "developer_reputation_label": rep_label,
            "developer_reputation_history": history_preview,
        },
        "repository_readme_excerpt": repository_readme[:4000],
        "pr_comments": comments_preview,
        "code_diff": code_diff[:40000],
    }
    return json.dumps(payload, ensure_ascii=False, indent=2)

# ---------------------------
# 6) GraphFlow (ä¿®å¤ç‰ˆ)
# ---------------------------

flow = GraphFlow(
    participants=builder.get_participants(),
    graph=execution_graph,
)

# ---------------------------
# 7) æ–‡ä»¶ä¿å­˜åŠŸèƒ½
# ---------------------------

def create_output_directory(project_name: str = "default") -> Path:
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    output_dir = Path("output") / project_name
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir

async def save_agent_output(agent_name: str, content: str, output_dir: Path):
    """ä¿å­˜agentè¾“å‡ºåˆ°æ–‡ä»¶"""
    try:
        filename = f"{agent_name}.json"
        filepath = output_dir / filename
        
        # å°è¯•è§£æJSONï¼Œå¦‚æœå¤±è´¥åˆ™ä½œä¸ºæ–‡æœ¬ä¿å­˜
        try:
            parsed_content = json.loads(content)
            async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(parsed_content, ensure_ascii=False, indent=2))
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯JSONï¼Œåˆ™ä½œä¸ºæ–‡æœ¬ä¿å­˜
            text_filename = filename.replace('.json', '.txt')
            text_filepath = output_dir / text_filename
            async with aiofiles.open(text_filepath, 'w', encoding='utf-8') as f:
                await f.write(content)
        
        print(f"âœ… å·²ä¿å­˜ {agent_name} è¾“å‡ºåˆ°: {filepath}")
        return str(filepath)
    except Exception as e:
        print(f"âŒ ä¿å­˜ {agent_name} è¾“å‡ºå¤±è´¥: {str(e)}")
        return None

async def save_complete_review_report(review_data: Dict[str, Any], output_dir: Path):
    """ä¿å­˜å®Œæ•´çš„å®¡æŸ¥æŠ¥å‘Š"""
    try:
        timestamp = int(time.time())
        filename = f"å®Œæ•´å®¡æŸ¥æŠ¥å‘Š_{timestamp}.json"
        filepath = output_dir / filename
        
        async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(review_data, ensure_ascii=False, indent=2))
        print(f"âœ… å·²ä¿å­˜å®Œæ•´å®¡æŸ¥æŠ¥å‘Šåˆ°: {filepath}")
        return str(filepath)
    except Exception as e:
        print(f"âŒ ä¿å­˜å®Œæ•´å®¡æŸ¥æŠ¥å‘Šå¤±è´¥: {str(e)}")
        return None

# ---------------------------
# 8) Example tasks
# ---------------------------

async def complex_business_logic_example() -> str:
    code_diff = """
diff --git a/services/data_pipeline.py b/services/data_pipeline.py
new file mode 100644
index 0000000..bcdefg1
--- /dev/null
+++ b/services/data_pipeline.py
@@ -0,0 +1,35 @@
import pandas as pd
import json
from typing import List, Dict, Any
import asyncio
import aiofiles

class DataPipeline:
    def __init__(self, source_path: str):
        self.source_path = source_path
        self.processed_data = []
        self.errors = []
    
    async def load_data(self) -> List[Dict[str, Any]]:
        "å¼‚æ­¥åŠ è½½JSONæ•°æ®æ–‡ä»¶"
        try:
            async with aiofiles.open(self.source_path, 'r') as f:
                content = await f.read()
                return json.loads(content)
        except Exception as e:
            self.errors.append(f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
            return []
    
    def transform_data(self, raw_data: List[Dict]) -> pd.DataFrame:
        "è½¬æ¢æ•°æ®ä¸ºDataFrameæ ¼å¼"
        if not raw_data:
            return pd.DataFrame()
        
        # æå–ç‰¹å®šå­—æ®µå¹¶è½¬æ¢
        transformed = []
        for item in raw_data:
            try:
                new_item = {
                    'id': item.get('id'),
                    'name': item.get('name', '').upper(),
                    'value': float(item.get('value', 0)),
                    'category': item.get('category', 'unknown')
                }
                transformed.append(new_item)
            except (ValueError, TypeError) as e:
                self.errors.append(f"æ•°æ®è½¬æ¢é”™è¯¯: {str(e)}")
        
        return pd.DataFrame(transformed)
    
    async def run_pipeline(self) -> Dict[str, Any]:
        "æ‰§è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“"
        raw_data = await self.load_data()
        df = self.transform_data(raw_data)
        
        return {
            'data': df.to_dict('records'),
            'count': len(df),
            'errors': self.errors
        }
"""
    pr_comments = [
        {'body': 'ç¼ºå°‘æ•°æ®éªŒè¯æœºåˆ¶ï¼Œå¯èƒ½å¯¼è‡´ç©ºå€¼æˆ–å¼‚å¸¸æ•°æ®', 'id': 1, 'line': 18, 'path': 'services/data_pipeline.py'},
        {'body': 'transform_dataæ–¹æ³•ä¸­çš„å¼‚å¸¸å¤„ç†è¿‡äºå®½æ³›', 'id': 2, 'line': 26, 'path': 'services/data_pipeline.py'},
        {'body': 'å»ºè®®æ·»åŠ æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶', 'id': 3, 'line': 10, 'path': 'services/data_pipeline.py'},
        {'body': 'å¼‚æ­¥å¤„ç†å®ç°è‰¯å¥½ï¼Œä½†å¯ä»¥æ·»åŠ è¿›åº¦å›è°ƒ', 'id': 4, 'line': 33, 'path': 'services/data_pipeline.py'}
    ]
    developer_reputation_score = 72
    developer_reputation_history = [
        'PR#25ï¼š1ä¸ªä¸¥é‡é—®é¢˜ï¼Œ2ä¸ªä¸­ç­‰é—®é¢˜',
        'PR#24ï¼šä»£ç è´¨é‡è‰¯å¥½ï¼Œæ— ä¸¥é‡é—®é¢˜',
        'PR#23ï¼š3ä¸ªä¸­ç­‰é—®é¢˜ï¼Œ1ä¸ªè½»åº¦é—®é¢˜'
    ]
    repository_readme = "# æ•°æ®å¤„ç†å¹³å°\n\næœ¬å¹³å°æä¾›é«˜æ•ˆçš„æ•°æ®ETLç®¡é“ï¼Œæ”¯æŒå¤šç§æ•°æ®æºå’Œæ ¼å¼è½¬æ¢ã€‚\n\n## ç‰¹æ€§\n- å¼‚æ­¥æ•°æ®å¤„ç†\n- å¤šæ ¼å¼æ•°æ®æ”¯æŒ\n- å®æ—¶ç›‘æ§å’Œæ—¥å¿—è®°å½•"

    return build_prompt(
        code_diff,
        pr_comments,
        developer_reputation_score,
        developer_reputation_history,
        repository_readme,
    )

# ---------------------------
# 9) Main
# ---------------------------

async def collect_and_save_agent_outputs(flow, task: str):
    """æ”¶é›†å¹¶ä¿å­˜æ‰€æœ‰agentçš„è¾“å‡º"""
    output_dir = create_output_directory()
    agent_outputs = {}
    
    print("\n=== å¼€å§‹ä»£ç å®¡æŸ¥åˆ†æ ===\n")
    
    # ä½¿ç”¨æµå¼æ–¹å¼æ”¶é›†è¾“å‡ºï¼ŒåŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶
    current_agent = None
    current_content = []
    all_messages = []
    
    async for message in flow.run_stream(task=task):
        # æ”¶é›†æ‰€æœ‰æ¶ˆæ¯
        all_messages.append(message)
        
        # æå–agentåç§°å’Œå†…å®¹
        if hasattr(message, 'source') and message.source:
            current_agent = message.source
            
        if hasattr(message, 'content') and message.content:
            content = str(message.content).strip()
            if content:
                # å¦‚æœæ˜¯æ–°çš„agentå¼€å§‹å‘è¨€ï¼Œå…ˆä¿å­˜ä¸Šä¸€ä¸ªagentçš„è¾“å‡º
                if current_agent and len(current_content) > 0:
                    full_content = '\n'.join(current_content)
                    if current_agent not in agent_outputs:
                        await save_agent_output(current_agent, full_content, output_dir)
                        agent_outputs[current_agent] = full_content
                        current_content = []
                
                current_content.append(content)
                
                # å¯¹äºFinalReviewAggregatorAgentï¼Œç‰¹åˆ«å¤„ç†å…¶æœ€ç»ˆè¾“å‡º
                if current_agent == "FinalReviewAggregatorAgent":
                    # FinalReviewAggregatorAgentçš„è¾“å‡ºé€šå¸¸æ˜¯æœ€é•¿çš„ï¼ŒåŒ…å«äº†æ‰€æœ‰èšåˆå†…å®¹
                    # å¦‚æœå†…å®¹å¾ˆé•¿ä¸”åŒ…å«JSONæ ¼å¼ï¼Œè®¤ä¸ºæ˜¯æœ€ç»ˆè¾“å‡º
                    if len(content) > 100 and ('{' in content or '[' in content):
                        full_content = '\n'.join(current_content)
                        await save_agent_output(current_agent, full_content, output_dir)
                        agent_outputs[current_agent] = full_content
                        current_content = []
                else:
                    # å¯¹äºå…¶ä»–agentï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆè¾“å‡ºï¼ˆJSONæ ¼å¼ï¼‰
                    if content.startswith('{') or content.startswith('['):
                        full_content = '\n'.join(current_content)
                        if current_agent and current_agent not in agent_outputs:
                            await save_agent_output(current_agent, full_content, output_dir)
                            agent_outputs[current_agent] = full_content
                        current_content = []
    
    # ä¿å­˜å‰©ä½™çš„å†…å®¹
    if current_content and current_agent:
        full_content = '\n'.join(current_content)
        if current_agent not in agent_outputs:
            await save_agent_output(current_agent, full_content, output_dir)
            agent_outputs[current_agent] = full_content
    
    # ä¿å­˜å®Œæ•´æŠ¥å‘Š
    complete_report = {
        "æ—¶é—´æˆ³": time.strftime("%Y-%m-%d %H:%M:%S"),
        "ä»»åŠ¡": task[:200] + "..." if len(task) > 200 else task,
        "agentè¾“å‡º": agent_outputs,
        "å®¡æŸ¥ç»“æœæ±‡æ€»": {
            "å‚ä¸çš„agentæ•°é‡": len(agent_outputs),
            "åŒ…å«çš„agent": list(agent_outputs.keys()),
        },
        "æœ€ç»ˆå®¡æŸ¥ç»“æœ": agent_outputs.get("FinalReviewAggregatorAgent", "æœªç”Ÿæˆ")
    }
    
    await save_complete_review_report(complete_report, output_dir)
    
    return agent_outputs

async def main():
    task = await complex_business_logic_example()

    print("\n--- å‡†å¤‡è¿è¡Œä»£ç å®¡æŸ¥ç³»ç»Ÿ ---\n")
    print("ğŸ“‹ ä»»åŠ¡å†…å®¹:")
    print(task[:300] + "..." if len(task) > 300 else task)
    
    # æ”¶é›†å¹¶ä¿å­˜agentè¾“å‡º
    agent_outputs = await collect_and_save_agent_outputs(flow, task)
    
    print("\n--- å®¡æŸ¥å®Œæˆ ---\n")
    print(f"ğŸ“Š æ€»å…±æ”¶é›†åˆ° {len(agent_outputs)} ä¸ªagentçš„è¾“å‡º")
    print("ğŸ“ æ‰€æœ‰è¾“å‡ºå·²ä¿å­˜åˆ° 'output' ç›®å½•")

if __name__ == "__main__":
    asyncio.run(main())
